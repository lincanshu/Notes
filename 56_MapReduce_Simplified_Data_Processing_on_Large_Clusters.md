# 初步印象
- 大名鼎鼎的MapReduce论文，考虑目前在研究工业互联网平台，其中联邦学习的本质就是分布式机器学习，这肯定是离不开分布式计算的，所以研究一下本文看看能不能找到一些灵感，期望是对未来工作的核心算法有推动作用。

# 简单概括
- 核心的编程模型就是Map和Reduce，Map函数做的事情是将键值对切分生成一个中间键值对的集合，Reduce函数做的事情是将所有的与中间健相关的中间值进行合并，在我看来有点像是分治算法，但是分布式算法不就是先分后并吗？
- 首先，结合李沐讲解论文的视频，我理解到本论文是一个系统实现类型的论文，这意味这其中最大的贡献在于系统设计的思路，还有系统实现的代码量（有可能是开源的），这就代表了其中不会有太多的公式，同时不会有太多有意思的算法。

# 有待改进

# 好奇1：简单讲讲整个工作流程？
- MapReduce首先把输入文件分成m份切片，每份16MB或者64MB
- 集群中分为master节点和worker节点，前者选择空闲的worker进行map和reduce的任务分配
- worker分配到一个map任务会读取对应输入切片的内容，由map函数生成的中间键值对会缓存在内存中
- 缓存的键值对将会被写入本地磁盘，并将具体位置返回给master，方便后续reduce任务的完成
- 当一个reduce工作节点被master节点召唤后，会调用RPC来读取map worker的本地磁盘的缓存数据
- reduce worker会遍历所有排完序的中间数据，并结合中间键完成统计
- 当所有的map任务和reduce任务完成后，master节点会唤醒用户程序

# 好奇2：作者从工作中学到三件事情
- 限制编程模型使我们易于并行化和分布式计算
- 网络带宽是稀缺资源，该系统的大量优化专注于减少网络中数据的发送
- 冗余的计算用于减小旧机器的影响，以及处理机器失败和数据丢失


