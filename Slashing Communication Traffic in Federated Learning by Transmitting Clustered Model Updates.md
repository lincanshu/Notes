# 提出的问题
- 在联邦学习中，客户端和中心服务器之间的模型参数传输会产生庞大的通信开销，目前的联邦学习中仍看不到一个适合的上行链路和下行链路压缩的灵活无偏压缩算法，无偏压缩算法可以确保模型收敛却无法保证模型精确度，有偏压缩算法可以实现较高的压缩率却无法保证模型的收敛。

# 解决的方法
- 作者提出了不损害模型精度的模型压缩算法MUCSC来减少通信的容量，并从理论上证明了该算法能够实现与不压缩情况下具备相同的收敛速率，之后进一步提出了一种有偏算法B-MUCSC，可以将压缩率提高10倍以上。

# 解决方案/算法


# 引用