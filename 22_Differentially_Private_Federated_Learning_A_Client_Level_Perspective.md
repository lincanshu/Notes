# 初步印象
- 这篇在早期的时候进行过精读，是发表于NIPS 2017的顶会论文，后来会议改了名字NeurIPS，考虑到近期看了不少文献，但是对于实际代码了解甚少，特此回过头fork代码并编译运行，期望是通过理解code和paper里算法等细节的关系，来加深对于联邦学习和差分隐私的理解

# 简单概括
- 本文面对的问题是易受差分攻击的联邦学习，提出了客户端视角下的差分隐私保护的联邦优化算法，目标是隐藏用户在训练过程中的贡献，平衡好隐私损失和模型性能，最后通过实验表明，差分隐私站在客户端视角来看具备可行性，另外，参与联邦学习的客户端数量足够时会有较高的模型精度，能够在损耗小部分的模型性能下保障用户的隐私。
- 给我科研上的启发是，复现代码这种可以考虑研究研究相关课题前沿的开源框架，这里是PATE，从论文的角度理解他们的工作，再从代码的角度去理解工作，从而达到深入理解的效果，以前对开源项目代码感到恐惧，其实根本没必要，哪里不懂就学哪里，缺什么补什么。

# 好奇1 : 具体的算法细节，其实很简单，算了一下毕竟是5年前的东西
- 作者把随机化机制引入联邦学习，主要目标是确保模型无法暴露出客户端是否参与了训练，作者说主要把随机化引入模型聚合的步骤，第一步是随机子采样，就是在模型聚合之后，随机选择一些客户端分发全局模型，客户端比对本地模型和全局模型，并将梯度发送回中心服务器；第二步是distort，本质就是将收集到的所有梯度进行阈值裁剪，添加高斯噪声后再合并。
- 从参考文献看来，属于是较早期将差分隐私引入联邦学习的论文之一，所以在客户端视角来看的话，首次采用高斯机制到中心模型更新是很新颖的做法，而且当客户端数量足够多的时候，对准确率影响不大。

# 好奇2 : 居然还提供了开源代码，回过头来试着跑跑看
- https://github.com/SAP-samples/machine-learning-diff-private-federated-learning
- 不知是因为五年前的代码，还是自己对于python3还不够熟悉，复现代码总是存在磕磕碰碰的，如果跑不起来可以先参照代码算法来理解。

# 好奇3 ： 对于实验也是比较有意思的
- 将MNIST数据集切成碎片，每个客户端拿到两个碎片，这样大多数的客户端只有两个数字，故单一客户端绝不可能训练出高精度地识别全部的十个数字的模型，固定了eplison参数为8，追踪隐私损耗。
